#statistica 

#### Entropia

Dato un campione $\{a_1,...,a_n\}$ in cui occorrono i valori distinti $v_1,...,v_s$ e indicando con $f_i$ la frequenza relativa dell'elemento $v_i$ per $i=1,...,s$, la quantità 
$$
H = \sum_{i=1}^{s}f_i \log \frac{1}{f_i} = -\sum_{i=1}^{s}f_i \log f_i
$$
è detta ***indice di entropia*** del campione.

> La scelta della base del logaritmo mi da' l'unità di misura, per esempio se scelgo $2$ misuro il valore dell'entropia in "bit"

Si noti che:
-  Per ogni $i$ vale $-f_i \log f_i \ge 0$, dunque $H \ge 0$.
-  Per ogni $i$ vale $-f_i \log f_i = 0$ se e solo se $f_i = 0$ oppure $f_i = 1$, pertanto $H = 0$ se e solo se ci si trova in condizione di minima eterogeneità (tutti gli elementi assumono lo stesso valore).
- In caso invece di massima eterogeneità si avrà $f_i = \frac{1}{s}$ e quindi $H = \log s$.

Si può pertanto definire l'indice di entropia *normalizzato*:
$$
H'=\frac{H}{\log s}
$$

#### Alberi di decisione

L'***albero di decisione*** è un interessante classificatore basato sugli indici di eterogeneità. Un albero di decisione assegna *oggetti* a classi, dove un oggetto è descritto tramite un'osservazione che consiste in un vettore di valori per degli attributi prefissati. Per prima cosa si considera la *radice* dell'albero, e che p contrassegnato da una condizione che coinvolge i valori di uno o più attributi per l'oggetto che si vuole classificare. A seconda del valore di questa condizione, si percorre una delle due frecce partenti dalla radice. Se il nodo a cui si arriva è una foglia, in tale nodo è indicata la classe assegnata all'oggetto, altrimenti il nodo riporta un'altra condizione da valutare, iterando il comportamento precedente fino a che non si raggiunge una foglia e quindi si determina una classe per l'oggetto.

#### Matrice di confusione

Un modo efficace di valutare un classificatore in termini di falsi positivi e di falsi negativi consiste nel disegnare la ***matrice di confusione*** che mostra il numero di *falsi positivi* e di *falsi negativi* unitamente al numero di casi correttamente classificati, a loro volta divisi in *veri positivi* e *veri negativi*.

|          | Positivo | Negativo |
| -------- |:--------:|:--------:|
| Positivo |    VP    |    FP    |
| Negativo |    FN    |    VN    |
|          |    TP    |    TN    |

A partire da questa matrice è possibile derivare due indici che valutano separatamente la capacità del classificatore a lavorare correttamente con gli oggetti positivi e con quelli negativi:

- la **sensibilità**: intesa come frazione degli oggetti positivi che vengono correttamente classificati
$$
sensibilità = \frac{VP}{TP},
$$
- la **specificità**, analogamente intesa come frazione degli oggetti negativi che vengono correttamente classificati
$$
specificità = \frac{VN}{TN}.
$$
Una volta calcolati i valori per questi due indici, è possibile valutare il classificatore in funzione della posizione assunta dal punto di coordinate $(1 - specificità, sensibilità)$ sul piano cartesiano.

#### Tipi di classificatori

- ##### Classificatori costanti
Consideriamo il classificatore $CP$ che associa indiscriminatamente gli oggetti nella classe positiva. La corrispondente matrice di confusione sarà la seguente.

|          | Positivo | Negativo |
| -------- |:--------:|:--------:|
| Positivo |    TP    |    TN    |
| Negativo |    0    |    0    |

Tutti i $TP$ oggetti positivi verranno assegnati alla classe positiva, e tutti i $TN$ oggetti negativi saranno assegnati alla classe positiva. Ciò significa che il numero di veri positivi sarà pari a $TP$ e il numero di veri negativi sarà zero: pertanto la *sensibilità* sarà uguale a $1$, mentre la *specificità* sarà nulla. Il classificatore $CP$ individuerà quindi il punto di coordinate $(1 - specificità, sensibilità) = (1, 1)$.

>
>CURVA ROC E CLASSIFICATORE SOGLIA

#### Analysis of variance (ANOVA)

