#statistica 

#### Teorema della probabilità totale

Se $E$ e $F$ sono due eventi qualsiasi, allora:
$$
\mathbb{P}(E \cup F) = \mathbb{P}(E) + \mathbb{P}(F) - \mathbb{P}(E \cap F)
$$
*Dimostrazione*: Per dimostrare facilmente questo teorema utilizzeremo il diagramma di Venn.

![[L06 2023-03-31 09.52.02.excalidraw|1000x200]]

Possiamo notare infatti che le regioni $I, II, III$ sono disgiunte, di conseguenza si può applicare il terzo assioma per ottenere:
$$
\begin{aligned}
\mathbb{P}(E \cup F) &= \mathbb{P}(I) + \mathbb{P}(II) - \mathbb{P}(III) \\
\mathbb{P}(E) &= \mathbb{P}(I) + \mathbb{P}(II) \\
\mathbb{P}(F) &= \mathbb{P}(II) + \mathbb{P}(III)
\end{aligned}
$$
Ora confrontando aggiungendo e sottraendo $\mathbb{P}(II)$, possiamo scrivere:
$$
\mathbb{P}(E \cup F) = \mathbb{P}(I) + \mathbb{P}(II) + \mathbb{P}(III)+ \mathbb{P}(II) - \mathbb{P}(II)
$$
e per sostituzione otteniamo:
$$
\mathbb{P}(E \cup F) = \mathbb{P}(E) + \mathbb{P}(F) - \mathbb{P}(II) 
$$
e la dimostrazione si è conclusa, poiché $II = E \cap F$.

#### Spazi di esiti equiprobabili

Dato $\Omega = \{e_1, e_2,...,e_N\}$ con $N = \#esiti$
$$
\begin{aligned}
&\exists p \in \mathbb{R}^+ \text{ | } \forall i \text{ } \mathbb{P}(\{e_i\}) = p\\
&1 = \mathbb{P}(\Omega) = \mathbb{P}(\bigcup_{i=1}^{N}\{e_i\}) = \sum_{i=1}^N{\mathbb{P}(e_i)}
\end{aligned}
$$
dunque: $$\sum_{i=1}^N{p} = Np \rightarrow p = \frac{1}{N}$$
Sempre tenendo conto di $p = \frac{1}{N}$, possiamo generalizzare per qualsiasi evento $E \in \mathcal{A}$ con $E = \{e_{i1}, e_{i2}, ..., e_{ik}\} = \bigcup_{j=1}^{k}\{e_{ij}\}$ 
$$
\mathbb{P}(E) = \mathbb{P}(\bigcup_{j=1}^{k}\{e_{ij}\}) = \sum_{j=1}^{k}\mathbb{P}(\{e_{ij}\}) = \frac{|E|}{N}
$$

#### Probabilità condizionata

La probabilità condizionata di un evento $A$ rispetto all'evento $B$ è definita come la probabilità dell'evento $A$, sapendo che l'evento $B$ si è verificato. Questa probabilità viene indicata con $\mathbb{P}(A|B)$ e rappresenta una correzione delle aspettative sulla probabilità di $A$, basata sull'osservazione di $B$. In altre parole, $\mathbb{P}(A|B)$ ci permette di stimare la probabilità dell'evento $A$, tenendo conto dell'informazione che abbiamo sull'evento $B$.

Sapendo che si è verificato $F$, affinché si verifichi anche $E$, l'evento dovrà contenere tutti quegli esiti che appartengono sia ad $F$ che ad $E$, ovvero che fanno parte di $E \cap F$. Essendosi verificato $F$, lo spazio dell'evento risultante deve essere ridotto, e per questo la probabilità condizionata dell'evento $E \cap F$ sarà pari al rapporto tra la sua probabilità e quella di $F$. In formula:
$$
\mathbb{P}(E|F) = \frac{\mathbb{P}(E \cap F)}{\mathbb{P}(F)}
$$
#### Formula di fattorizzazione

Con $F_i$ insiemi disgiunti:
$$
\bigcup_{i=1}^{n}F_i = \Omega
$$
chiamiamo *formula di fattorizzazione*, la seguente formula:
$$
\begin{aligned}
\mathbb{P}(E) &= \sum_{i=1}^{n}\mathbb{P}(E \cap F_i) \\
&=\sum_{i=1}^{n}\mathbb{P}(E|F_i)\mathbb{P}(F_i) \\
\end{aligned}
$$
grazie a questa formula possiamo calcolare la probabilità di un evento $E$ condizionando rispetto a quale si verifichi tra un gruppo di eventi accessori mutuamente esclusivi e che ricoprono $\Omega$.