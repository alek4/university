#statistica 

Esistono due diverse interpretazioni del concetto di *probabilità*:
- ***interpretazione frequentista***: la probabilità di un esito è considerata una proprietà dell'esito stesso. Determinata operativamente ripetendo in continuazione l'esperimento, come il rapporto tra il numero di casi in cui si è registrato l'esito sul totale ([[statistica/notes/L01#^1cf92d|frequenza relativa]])
- ***interpretazione soggettivistica***: si crede che la probabilità di un esito non sia una proprietà oggettiva, ma piuttosto la precisazione del livello di fiducia che lo studioso ripone nel verificarsi dell'esito.

L'insieme di tutti gli esiti possibili di un esperimento si dice ***insieme degli esiti*** (*spazio campionario, insieme universo, spazio degli esiti*) denotato con $\Omega$.

*es. (lancio di dadi):*
$$
\Omega = \{1,2,3,4,5,6\}
$$
*es. (peso di un supereroe):*
$$
\Omega = \mathbb{R}^+
$$

I sottoinsiemi dello *spazio degli esiti* si dicono ***eventi***:
$$
E \subseteq \Omega
$$
indicheremo un ***esito*** con: $e \in E$, se questo dovesse accadere durante un esperimento diremo che $E$ si è verificato.

*es. (lancio del dado con esito pari)*:
$$
E = \{2,4,6\}
$$
diremo che $E$ si è verificato se $e \in E$.

#### Operazioni insiemistiche

Dato che abbiamo definito gli eventi come insiemi, possiamo ora descrivere le operazioni che utilizzeremo:
- ***unione***, $E \cup F$ è l'insieme formato dagli esiti che stanno o in $E$ o in $F$. Dunque $E \cup F$ si verificherà se *almeno uno* tra $E$ e $F$ si verifica
- ***intersezione***, $E \cap F$ è l'insieme formato dagli esiti che sono presenti sia in $E$, sia in $F$. Come evento, rappresenta il verificarsi di *entrambi* gli eventi $E$ e $F$
- ***differenza***, $E \setminus F$ è l'insieme formato dagli esiti che sono presenti *solo* in $E$. Ovvero $e \in E \setminus F \Leftrightarrow e \in E \land e \notin F$ 

Un particolare tipo di evento è l'***evento vuoto***, ovvero un evento che non contiene esiti possibili per l'esperimento. Se $E \cap F = \varnothing$, ovvero se $E$ e $F$ non possono verificarsi entrambi, li diremo eventi *mutualmente esclusivi o disgiunti*. 

Per ogni evento $E$, definiamo l'evento $\overline E$, che chiameremo ***complementare*** di $E$, ovvero quell'evento tale che $\overline E = \Omega \setminus E$, in cui troveremo tutti gli esiti dello spazio degli esiti che *non* stanno in $E$. 

Se, per una coppia di eventi $E$ e $F$ accade che tutti gli esiti di $E$ appartengono anche ad $F$, si dice che $E \subseteq F$, questo significa che ogni esito che descrive $E$ descrive anche $F$ ($E \rightarrow F$).
Se vale per entrambi, $E \subseteq F$ e $F \subseteq E$, $E$ e $F$ sono uguali $E = F$.

#### Proprietà degli eventi

Gli operatore di unione, intersezione e complementare, obbediscono a regole non dissimili da quelle dell'algebra dell'addizione e della moltiplicazione dei numeri reali:
- proprietà commutativa: 
$$
A \cup B = B \cup A
$$
- proprietà associativa: 
$$A \cup (B \cup C) = (A \cup B) \cup C$$
- proprietà distributiva: 
$$
\begin{aligned}
A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\\ 
A \cap (B \cup C) = (A \cap B) \cup (A \cap C)
\end{aligned}
$$
- leggi di *De Morgan*: 
$$
\begin{aligned}
\overline{A \cup B} = \overline A \cap \overline B \\
\overline{A \cap B} = \overline A \cup \overline B
\end{aligned}
$$
#### Funzione di probabilità

Sia $\mathbb{P}: \mathcal{A} \rightarrow \mathbb{R}^+$ la ***funzione di probabilità***, che associa ad ogni evento $E$ appartenente all'***algebra di eventi*** $\mathcal{A}$ un numero che si dice *probabilità* dell'evento $E$.
Definiamo ora $\mathcal{A}$ come: $\mathcal{A} = \{E_1, E_2, ...\} \text{ } \forall i \text{ } E_i \subseteq \Omega$. Con le seguenti proprietà:
1. $\Omega \in \mathcal{A}$ 
2. $\forall E \text{ } E \in \mathcal{A} \rightarrow \overline E \in \mathcal{A}$
3. $\forall E,F \text{ } E \in \mathcal{A} \land F \in \mathcal{A} \rightarrow F \cup E \in \mathcal{A}$
con queste semplici proprietà possiamo definire anche l'intersezione, infatti: $$A \cap B = \overline {\overline{A \cap B}} = \overline {(\overline A \cup \overline B)}$$
Se $| \Omega | = n$, ovvero finito, $\mathcal{A} = 2^\Omega$ ovvero l'insieme delle parti di $\Omega$ (tutti i possibili sottoinsiemi di $\Omega$)

#### Assiomi di Kolmogorov

La probabilità degli eventi deve rispettare gli *assiomi di Kolmogorou*:
1. $\forall E \in \mathcal{A} \text{ } \mathbb{P}(E) \ge 0$
2. $\mathbb{P}(\Omega) = 1$
3. $\forall E,F \in \mathcal{A} \text{ } E \cap F = \varnothing \rightarrow \mathbb{P}(E \cup F) = \mathbb{P}(E) + \mathbb{P}(F)$

*Dimostrazioni*:
- $\mathbb{P}(\overline E) = 1 - \mathbb{P}(E)$
$$
\begin{aligned}
&1 = \mathbb{P}(\Omega) = \mathbb{P}(E \cup \overline E) = \mathbb{P}(E) + \mathbb{P}(\overline E)\\
&\mathbb{P}(\overline E) = 1 - \mathbb{P}(E)
\end{aligned}
$$
- $\forall E \in \mathcal{A} \text{ } \mathbb{P}(E) \le 1$
$$
\begin{aligned}
&E,F \in \mathcal{A} \\
&F = E \cup E' \\
&E' = F \setminus E \\
&E \cap E' = \varnothing \\
&\mathbb{P}(F) = \mathbb{P}(E \cup E') = \mathbb{P}(E) + \mathbb{P}(E') \ge \mathbb{P}(E) \\
&E \subseteq F \rightarrow \mathbb{P}(E) \le \mathbb{P}(F) \\
&E \subseteq \Omega \rightarrow \mathbb{P}(E) \le \mathbb{P}(\Omega) = 1
\end{aligned}
$$

#### Calcolo combinatorio

_Principio fondamentale del calcolo combinatorio_: se ci sono $𝑠1$ modi per operare una scelta e, per ciascuno di essi, ci sono $𝑠2$ modi per operare una seconda scelta e, per ciascuno di essi ci sono $𝑠3$ modi per operare una terza scelta e così via fino a $𝑠𝑡$ modi per operare la $𝑡$-esima scelta, allora il numero delle sequenze di possibili scelte è $𝑠1⋅𝑠2⋅𝑠3…𝑠𝑡$.

#### Permutazioni

Se gli 𝑛 oggetti di 𝐴 sono tutti **distinguibili**, allora si parla di _permutazione semplice_, o soltanto _permutazione_, degli 𝑛 oggetti. Il numero di possibili permutazioni semplici di $n$ oggetti è $n!$.

Se gli 𝑛 oggetti di 𝐴 **non sono tutti distinguibili**, ma sono distinguibili a gruppi di numerosità 𝑛1,𝑛2,…𝑛𝑘, allora una sequenza ordinata di tali oggetti che sia distinguibile dalle altre è detta _permutazione di oggetti distinguibili a gruppi_.

Se chiamiamo $𝑃_{𝑛;𝑛_1,…,𝑛_𝑘}$ il numero di configurazioni differenti e ricordiamo che il numero di permutazioni semplici è $𝑛!$, possiamo scrivere:
$$
𝑛!=𝑃_{𝑛;𝑛_1,…,𝑛_𝑘}⋅𝑛_1!⋅𝑛_2!…𝑛_𝑘!,
$$
da cui segue che il numero delle permutazioni di $n$ oggetti distinguibili a gruppi di numerosità $𝑛_1,𝑛_2,…𝑛_𝑘$ è:
$$
𝑃_{𝑛;𝑛_1,…,𝑛_𝑘}= \frac{𝑛!}{𝑛_1!⋅𝑛_2!…𝑛_𝑘!} = \binom{n}{n_1, n_2, ..., n_k}.
$$
Questa quantità è detta anche _coefficiente multinomiale_.

#### Disposizioni e combinazioni

Per calcolare il numero $𝑑_{𝑛,𝑘}$ di possibili _disposizioni senza ripetizione di 𝑛_ _oggetti distinti su 𝑘_ _posti_ procediamo in modo analogo a quanto fatto per le permutazioni semplici, fermandoci però alla posizione 𝑘-esima.
$$
𝑑_{𝑛,𝑘} = \frac{n!}{(n-k)!}
$$