#statistica 

Esistono due diverse interpretazioni del concetto di *probabilitÃ *:
- ***interpretazione frequentista***: la probabilitÃ  di un esito Ã¨ considerata una proprietÃ  dell'esito stesso. Determinata operativamente ripetendo in continuazione l'esperimento, come il rapporto tra il numero di casi in cui si Ã¨ registrato l'esito sul totale ([[statistica/notes/L01#^1cf92d|frequenza relativa]])
- ***interpretazione soggettivistica***: si crede che la probabilitÃ  di un esito non sia una proprietÃ  oggettiva, ma piuttosto la precisazione del livello di fiducia che lo studioso ripone nel verificarsi dell'esito.

L'insieme di tutti gli esiti possibili di un esperimento si dice ***insieme degli esiti*** (*spazio campionario, insieme universo, spazio degli esiti*) denotato con $\Omega$.

*es. (lancio di dadi):*
$$
\Omega = \{1,2,3,4,5,6\}
$$
*es. (peso di un supereroe):*
$$
\Omega = \mathbb{R}^+
$$

I sottoinsiemi dello *spazio degli esiti* si dicono ***eventi***:
$$
E \subseteq \Omega
$$
indicheremo un ***esito*** con: $e \in E$, se questo dovesse accadere durante un esperimento diremo che $E$ si Ã¨ verificato.

*es. (lancio del dado con esito pari)*:
$$
E = \{2,4,6\}
$$
diremo che $E$ si Ã¨ verificato se $e \in E$.

#### Operazioni insiemistiche

Dato che abbiamo definito gli eventi come insiemi, possiamo ora descrivere le operazioni che utilizzeremo:
- ***unione***, $E \cup F$ Ã¨ l'insieme formato dagli esiti che stanno o in $E$ o in $F$. Dunque $E \cup F$ si verificherÃ  se *almeno uno* tra $E$ e $F$ si verifica
- ***intersezione***, $E \cap F$ Ã¨ l'insieme formato dagli esiti che sono presenti sia in $E$, sia in $F$. Come evento, rappresenta il verificarsi di *entrambi* gli eventi $E$ e $F$
- ***differenza***, $E \setminus F$ Ã¨ l'insieme formato dagli esiti che sono presenti *solo* in $E$. Ovvero $e \in E \setminus F \Leftrightarrow e \in E \land e \notin F$ 

Un particolare tipo di evento Ã¨ l'***evento vuoto***, ovvero un evento che non contiene esiti possibili per l'esperimento. Se $E \cap F = \varnothing$, ovvero se $E$ e $F$ non possono verificarsi entrambi, li diremo eventi *mutualmente esclusivi o disgiunti*. 

Per ogni evento $E$, definiamo l'evento $\overline E$, che chiameremo ***complementare*** di $E$, ovvero quell'evento tale che $\overline E = \Omega \setminus E$, in cui troveremo tutti gli esiti dello spazio degli esiti che *non* stanno in $E$. 

Se, per una coppia di eventi $E$ e $F$ accade che tutti gli esiti di $E$ appartengono anche ad $F$, si dice che $E \subseteq F$, questo significa che ogni esito che descrive $E$ descrive anche $F$ ($E \rightarrow F$).
Se vale per entrambi, $E \subseteq F$ e $F \subseteq E$, $E$ e $F$ sono uguali $E = F$.

#### ProprietÃ  degli eventi

Gli operatore di unione, intersezione e complementare, obbediscono a regole non dissimili da quelle dell'algebra dell'addizione e della moltiplicazione dei numeri reali:
- proprietÃ  commutativa: 
$$
A \cup B = B \cup A
$$
- proprietÃ  associativa: 
$$A \cup (B \cup C) = (A \cup B) \cup C$$
- proprietÃ  distributiva: 
$$
\begin{aligned}
A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\\ 
A \cap (B \cup C) = (A \cap B) \cup (A \cap C)
\end{aligned}
$$
- leggi di *De Morgan*: 
$$
\begin{aligned}
\overline{A \cup B} = \overline A \cap \overline B \\
\overline{A \cap B} = \overline A \cup \overline B
\end{aligned}
$$
#### Funzione di probabilitÃ 

Sia $\mathbb{P}: \mathcal{A} \rightarrow \mathbb{R}^+$ la ***funzione di probabilitÃ ***, che associa ad ogni evento $E$ appartenente all'***algebra di eventi*** $\mathcal{A}$ un numero che si dice *probabilitÃ * dell'evento $E$.
Definiamo ora $\mathcal{A}$ come: $\mathcal{A} = \{E_1, E_2, ...\} \text{ } \forall i \text{ } E_i \subseteq \Omega$. Con le seguenti proprietÃ :
1. $\Omega \in \mathcal{A}$ 
2. $\forall E \text{ } E \in \mathcal{A} \rightarrow \overline E \in \mathcal{A}$
3. $\forall E,F \text{ } E \in \mathcal{A} \land F \in \mathcal{A} \rightarrow F \cup E \in \mathcal{A}$
con queste semplici proprietÃ  possiamo definire anche l'intersezione, infatti: $$A \cap B = \overline {\overline{A \cap B}} = \overline {(\overline A \cup \overline B)}$$
Se $| \Omega | = n$, ovvero finito, $\mathcal{A} = 2^\Omega$ ovvero l'insieme delle parti di $\Omega$ (tutti i possibili sottoinsiemi di $\Omega$)

#### Assiomi di Kolmogorov

La probabilitÃ  degli eventi deve rispettare gli *assiomi di Kolmogorou*:
1. $\forall E \in \mathcal{A} \text{ } \mathbb{P}(E) \ge 0$
2. $\mathbb{P}(\Omega) = 1$
3. $\forall E,F \in \mathcal{A} \text{ } E \cap F = \varnothing \rightarrow \mathbb{P}(E \cup F) = \mathbb{P}(E) + \mathbb{P}(F)$

*Dimostrazioni*:
- $\mathbb{P}(\overline E) = 1 - \mathbb{P}(E)$
$$
\begin{aligned}
&1 = \mathbb{P}(\Omega) = \mathbb{P}(E \cup \overline E) = \mathbb{P}(E) + \mathbb{P}(\overline E)\\
&\mathbb{P}(\overline E) = 1 - \mathbb{P}(E)
\end{aligned}
$$
- $\forall E \in \mathcal{A} \text{ } \mathbb{P}(E) \le 1$
$$
\begin{aligned}
&E,F \in \mathcal{A} \\
&F = E \cup E' \\
&E' = F \setminus E \\
&E \cap E' = \varnothing \\
&\mathbb{P}(F) = \mathbb{P}(E \cup E') = \mathbb{P}(E) + \mathbb{P}(E') \ge \mathbb{P}(E) \\
&E \subseteq F \rightarrow \mathbb{P}(E) \le \mathbb{P}(F) \\
&E \subseteq \Omega \rightarrow \mathbb{P}(E) \le \mathbb{P}(\Omega) = 1
\end{aligned}
$$

#### Calcolo combinatorio

_Principio fondamentale del calcolo combinatorio_: se ci sono $ğ‘ 1$ modi per operare una scelta e, per ciascuno di essi, ci sono $ğ‘ 2$ modi per operare una seconda scelta e, per ciascuno di essi ci sono $ğ‘ 3$ modi per operare una terza scelta e cosÃ¬ via fino a $ğ‘ ğ‘¡$ modi per operare la $ğ‘¡$-esima scelta, allora il numero delle sequenze di possibili scelte Ã¨ $ğ‘ 1â‹…ğ‘ 2â‹…ğ‘ 3â€¦ğ‘ ğ‘¡$.

#### Permutazioni

Se gli ğ‘› oggetti di ğ´ sono tutti **distinguibili**, allora si parla di _permutazione semplice_, o soltanto _permutazione_, degli ğ‘› oggetti. Il numero di possibili permutazioni semplici di $n$ oggetti Ã¨ $n!$.

Se gli ğ‘› oggetti di ğ´ **non sono tutti distinguibili**, ma sono distinguibili a gruppi di numerositÃ  ğ‘›1,ğ‘›2,â€¦ğ‘›ğ‘˜, allora una sequenza ordinata di tali oggetti che sia distinguibile dalle altre Ã¨ detta _permutazione di oggetti distinguibili a gruppi_.

Se chiamiamo $ğ‘ƒ_{ğ‘›;ğ‘›_1,â€¦,ğ‘›_ğ‘˜}$ il numero di configurazioni differenti e ricordiamo che il numero di permutazioni semplici Ã¨ $ğ‘›!$, possiamo scrivere:
$$
ğ‘›!=ğ‘ƒ_{ğ‘›;ğ‘›_1,â€¦,ğ‘›_ğ‘˜}â‹…ğ‘›_1!â‹…ğ‘›_2!â€¦ğ‘›_ğ‘˜!,
$$
da cui segue che il numero delle permutazioni di $n$ oggetti distinguibili a gruppi di numerositÃ  $ğ‘›_1,ğ‘›_2,â€¦ğ‘›_ğ‘˜$ Ã¨:
$$
ğ‘ƒ_{ğ‘›;ğ‘›_1,â€¦,ğ‘›_ğ‘˜}= \frac{ğ‘›!}{ğ‘›_1!â‹…ğ‘›_2!â€¦ğ‘›_ğ‘˜!} = \binom{n}{n_1, n_2, ..., n_k}.
$$
Questa quantitÃ  Ã¨ detta anche _coefficiente multinomiale_.

#### Disposizioni e combinazioni

Per calcolare il numero $ğ‘‘_{ğ‘›,ğ‘˜}$ di possibili _disposizioni senza ripetizione di ğ‘›_ _oggetti distinti su ğ‘˜_ _posti_ procediamo in modo analogo a quanto fatto per le permutazioni semplici, fermandoci perÃ² alla posizione ğ‘˜-esima.
$$
ğ‘‘_{ğ‘›,ğ‘˜} = \frac{n!}{(n-k)!}
$$