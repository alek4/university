#sistemi-operativi  

La schedulazione è una funzione dei sistemi operativi che gestisce l'esecuzione dei processi sulla CPU, cercando di ottimizzarne l'utilizzo. Ciò viene fatto definendo delle politiche di ordinamento dei processi che determinano quale processo deve essere eseguito in un determinato momento. Un processo può alternare fasi di computazione svolte dal processore (picco di CPU) e fasi di attesa di una periferica (picco di I/O). La durata dei picchi del processore varia da processo a processo e da macchina a macchina, ma in media è di circa 8 millisecondi. I processi di classe I/O-bound hanno molti picchi brevi della CPU, mentre quelli CPU-bound hanno pochi picchi ma lunghi. La scelta dell'algoritmo di schedulazione dipende da queste considerazioni.

Ci sono due modi per attivare la schedulazione: con rilascio forzato e senza rilascio forzato. La schedulazione senza rilascio forzato è nota come schedulazione non pre-emptive e funziona in questo modo: una volta che la CPU viene assegnata a un processo, questo la mantiene finché non accade una delle seguenti cose:

-   il processo in esecuzione entra in uno stato di attesa (ad esempio dopo aver richiesto un'operazione di I/O o aspettando il termine di uno dei suoi figli)
-   il processo in esecuzione entra in uno stato di pronto (ad esempio quando si verifica un interrupt)
-   il processo rilascia volontariamente la CPU
-   il processo termina

Quando uno di questi eventi si verifica, viene selezionato un altro processo dallo schedulatore per essere eseguito. La schedulazione non pre-emptive è quindi sincrona con l'evoluzione dello stato della computazione.

Nel caso di sistemi multi-tasking a condivisione di tempo (time sharing), è necessario utilizzare un altro metodo per attivare lo schedulatore, che è asincrono rispetto alla computazione. Questo metodo prevede il rilascio forzato del processo in esecuzione quando scade il quanto di tempo assegnato al processo. Questo tipo di schedulazione è chiamata schedulazione con rilascio forzato o schedulazione pre-emptive. Tuttavia, questo tipo di schedulazione può avere un costo legato all'accesso ai dati condivisi. Ad esempio, se due processi condividono dei dati e uno di essi li sta modificando quando scade il suo time slice e viene terminato forzatamente, il secondo processo potrebbe trovare i dati in uno stato inconsistente quando cerca di leggerli. Per evitare questo tipo di problemi, è necessario utilizzare meccanismi di sincronizzazione.

Ci sono tre tipi di schedulazione, che agiscono su diversi livelli temporali: a breve termine, a medio termine e a lungo termine. La schedulazione a breve termine, nota anche come CPU-scheduler, ordina i processi già presenti in memoria centrale e pronti per l'esecuzione. Viene eseguita frequentemente per garantire una turnazione rapida dei processi. L'algoritmo che implementa la schedulazione a breve termine deve essere veloce per minimizzare il carico di gestione. La schedulazione a lungo termine, nota anche come long-term scheduler o job scheduler, ordina tutti i processi attivati nel sistema, compresi quelli presenti nelle memorie di massa, e seleziona quelli da caricare in memoria centrale per l'esecuzione. Gli algoritmi di schedulazione a lungo termine sono di solito lenti e complessi perché scegliere la combinazione più adeguata di processi da caricare dalle memorie ausiliari per sfruttare al meglio la CPU non è semplice. La schedulazione a medio termine, nota anche come mid-term scheduler, si trova a un livello intermedio tra i due precedenti e viene tipicamente implementata in sistemi multi-utente per gestire la memoria centrale. Ha come obiettivo evitare che i processi rimangano bloccati nella memoria per troppo tempo, spostandoli in memoria ausiliaria se non vengono utilizzati. Gli algoritmi di schedulazione a medio termine devono essere rapidi ma anche flessibili, perché devono adattarsi ai cambiamenti dei processi in esecuzione.

Esistono tre modi per valutare la bontà di un algoritmo di schedulazione. Il primo modo è la valutazione analitica, che prevede l'utilizzo di modelli matematici per definire le prestazioni dell'algoritmo in base a un carico di lavoro prestabilito. Questo metodo è semplice e preciso, ma i risultati ottenuti non sono generalizzabili e non tengono conto del fatto che il carico di lavoro reale non è costante. Il secondo modo è la valutazione statistica, che permette di ottenere risultati con un grado di incertezza associato. Un esempio di valutazione statistica è la modellazione a reti di code, che utilizza distribuzioni di picchi di CPU e IO e considera il computer come una rete di servizi, ciascuno con una coda associata. Un altro esempio di valutazione statistica è la simulazione, che consiste nella realizzazione di un modello software del sistema per testare il comportamento dell'algoritmo. I dati in input alla simulazione possono essere picchi di CPU e IO generati casualmente o la traccia di un sistema reale. Il terzo modo è l'implementazione, che consiste nell'utilizzo degli strumenti di rilevazione del sistema per valutare l'efficienza dell'algoritmo nel sistema reale. Questo metodo è il più accurato, ma richiede tempo e collaborazione da parte degli utenti. Inoltre, per ottenere le prestazioni migliori in diverse situazioni può essere necessario implementare più algoritmi di schedulazione e decidere se analizzare i casi singolarmente o studiare i valori medi.

Alcuni algoritmi di schedulazione:
1.  Scheduling in ordine d'arrivo (**FCFS**, First-Come-First-Served): in questo algoritmo, le attività vengono eseguite in base all'ordine di arrivo. Ad esempio, se due processi vengono inviati contemporaneamente al sistema, il processo che arriva per prima verrà eseguito per primo. Viene realizzato con una semplice coda FIFO, un aspetto negativo di questo algoritmo è che generalmente il tempo di attesa, per ogni processo, è abbastanza lungo. Questo algoritmo è senza prelazione; una volta che la CPU è assegnata ad un processo, essa verrà trattenuta fino al momento del rilascio

2.  Scheduling shortest-job-first (**SJF**, Shortest Job First): in questo algoritmo, le attività vengono eseguite in base alla loro durata prevista. Ad esempio, se due attività hanno durata prevista diversa, l'attività più breve verrà eseguita per prima. Tale politica di schedulazione è quella ottimale, poiché fornisce sempre il minor tempo di attesa medio per un dato gruppo di processi. Se infatti eseguo prima i processi più brevi il loro tempo di attesa diminuisce molto più di quanto possa aumentare quello dei processi più lunghi, diminuendo di conseguenza il tempo medio. A differenza del precedente, questo algoritmo può essere implementato con e senza prelazione.

3.  Scheduling con priorità: in questo algoritmo, ogni attività viene assegnata una priorità e l'algoritmo di scheduling esegue prima le attività con priorità più alta

4.  Scheduling circolare (**Round-Robin**): in questo algoritma, ogni attività viene eseguita per un determinato periodo di tempo (noto come "quantum"), dopodiché viene interrotta e l'esecuzione viene passata alla prossima attività nella coda.

5.  Scheduling a code multilivello (Multilevel Queue Scheduling): in questo algoritmo, le attività vengono suddivise in diverse code in base alla loro priorità o alla loro tipologia. Ad esempio, potrebbero esserci code per attività di sistema, attività di utente e attività di background.

6.  Scheduling a code multilivello con retroazione (Multilevel Feedback Queue Scheduling): in questo algoritmo, le attività vengono suddivise in diverse code in base alla loro priorità o alla loro tipologia, come nel caso dell'algoritmo di scheduling a code multilivello. Inoltre, le attività che hanno trascorso molto tempo in una data coda possono essere trasferite in una coda con priorità più bassa. Questo permette di evitare che le attività rimangano bloccate in una coda per un tempo eccessivo.

#TODO